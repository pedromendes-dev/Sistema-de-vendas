import { Pool } from "pg";
import { config } from "dotenv";

config();

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

async function optimizeServer() {
  console.log("üöÄ Iniciando otimiza√ß√£o do servidor...\n");

  try {
    // 1. Otimizar configura√ß√µes do PostgreSQL para o servidor
    console.log("1. Otimizando configura√ß√µes do PostgreSQL...");

    const serverOptimizations = [
      // Configura√ß√µes de conex√£o
      "SET max_connections = 100",
      "SET shared_preload_libraries = 'pg_stat_statements'",

      // Configura√ß√µes de performance
      "SET work_mem = '256MB'",
      "SET maintenance_work_mem = '256MB'",
      "SET shared_buffers = '256MB'",
      "SET effective_cache_size = '1GB'",
      "SET random_page_cost = 1.1",
      "SET effective_io_concurrency = 200",

      // Configura√ß√µes de paralelismo
      "SET max_parallel_workers_per_gather = 2",
      "SET max_parallel_workers = 4",
      "SET max_worker_processes = 8",

      // Configura√ß√µes de logging
      "SET log_statement = 'all'",
      "SET log_min_duration_statement = 1000",
      "SET log_checkpoints = on",
      "SET log_connections = on",
      "SET log_disconnections = on",

      // Configura√ß√µes de WAL
      "SET wal_buffers = '16MB'",
      "SET checkpoint_completion_target = 0.9",
      "SET wal_writer_delay = '200ms'",

      // Configura√ß√µes de autovacuum
      "SET autovacuum = on",
      "SET autovacuum_max_workers = 3",
      "SET autovacuum_naptime = '1min'",
      "SET autovacuum_vacuum_threshold = 50",
      "SET autovacuum_analyze_threshold = 50",

      // Configura√ß√µes de timeout
      "SET statement_timeout = '30s'",
      "SET lock_timeout = '5s'",
      "SET idle_in_transaction_session_timeout = '10min'",

      // Configura√ß√µes de cache
      "SET effective_io_concurrency = 200",
      "SET seq_page_cost = 1.0",
      "SET cpu_tuple_cost = 0.01",
      "SET cpu_index_tuple_cost = 0.005",
      "SET cpu_operator_cost = 0.0025",
    ];

    for (const optimization of serverOptimizations) {
      try {
        await pool.query(optimization);
        console.log(`‚úÖ Configura√ß√£o aplicada: ${optimization.split(" ")[1]}`);
      } catch (error) {
        console.log(
          `‚ö†Ô∏è Configura√ß√£o n√£o aplicada: ${optimization.split(" ")[1]} - ${
            error.message
          }`
        );
      }
    }

    // 2. Criar fun√ß√µes de cache e otimiza√ß√£o
    console.log("\n2. Criando fun√ß√µes de cache e otimiza√ß√£o...");

    const cacheFunctions = [
      `CREATE OR REPLACE FUNCTION get_cached_sales_summary()
       RETURNS TABLE (
         attendant_id INTEGER,
         attendant_name TEXT,
         total_sales BIGINT,
         total_revenue DECIMAL,
         average_ticket DECIMAL
       ) AS $$
       BEGIN
         RETURN QUERY
         SELECT 
           a.id,
           a.name,
           COUNT(s.id)::BIGINT,
           COALESCE(SUM(s.value), 0),
           COALESCE(AVG(s.value), 0)
         FROM attendants a
         LEFT JOIN sales s ON a.id = s.attendant_id
         GROUP BY a.id, a.name
         ORDER BY total_revenue DESC;
       END;
       $$ LANGUAGE plpgsql STABLE`,

      `CREATE OR REPLACE FUNCTION get_cached_monthly_performance(months_back INTEGER DEFAULT 12)
       RETURNS TABLE (
         attendant_id INTEGER,
         attendant_name TEXT,
         month DATE,
         sales_count BIGINT,
         revenue DECIMAL,
         avg_ticket DECIMAL
       ) AS $$
       BEGIN
         RETURN QUERY
         SELECT 
           a.id,
           a.name,
           DATE_TRUNC('month', s.created_at)::DATE,
           COUNT(s.id)::BIGINT,
           COALESCE(SUM(s.value), 0),
           COALESCE(AVG(s.value), 0)
         FROM attendants a
         LEFT JOIN sales s ON a.id = s.attendant_id
         WHERE s.created_at >= CURRENT_DATE - (months_back || ' months')::INTERVAL
         GROUP BY a.id, a.name, DATE_TRUNC('month', s.created_at)
         ORDER BY month DESC, revenue DESC;
       END;
       $$ LANGUAGE plpgsql STABLE`,

      `CREATE OR REPLACE FUNCTION get_cached_leaderboard()
       RETURNS TABLE (
         attendant_id INTEGER,
         attendant_name TEXT,
         total_points INTEGER,
         current_streak INTEGER,
         best_streak INTEGER,
         rank INTEGER
       ) AS $$
       BEGIN
         RETURN QUERY
         SELECT 
           a.id,
           a.name,
           COALESCE(l.total_points, 0),
           COALESCE(l.current_streak, 0),
           COALESCE(l.best_streak, 0),
           COALESCE(l.rank, 0)
         FROM attendants a
         LEFT JOIN leaderboard l ON a.id = l.attendant_id
         ORDER BY l.total_points DESC NULLS LAST;
       END;
       $$ LANGUAGE plpgsql STABLE`,

      `CREATE OR REPLACE FUNCTION get_cached_goal_progress()
       RETURNS TABLE (
         goal_id INTEGER,
         attendant_name TEXT,
         title TEXT,
         target_value DECIMAL,
         current_value DECIMAL,
         progress_percentage DECIMAL,
         status TEXT
       ) AS $$
       BEGIN
         RETURN QUERY
         SELECT 
           g.id,
           a.name,
           g.title,
           g.target_value,
           g.current_value,
           CASE 
             WHEN g.current_value >= g.target_value THEN 100
             ELSE (g.current_value / g.target_value * 100)
           END,
           CASE 
             WHEN g.end_date < CURRENT_DATE THEN 'Vencida'
             WHEN g.current_value >= g.target_value THEN 'Conclu√≠da'
             WHEN g.is_active = 0 THEN 'Finalizada'
             ELSE 'Em andamento'
           END
         FROM goals g
         JOIN attendants a ON g.attendant_id = a.id
         WHERE g.is_active = 1
         ORDER BY g.end_date ASC;
       END;
       $$ LANGUAGE plpgsql STABLE`,
    ];

    for (const functionQuery of cacheFunctions) {
      try {
        await pool.query(functionQuery);
        console.log(`‚úÖ Fun√ß√£o de cache criada`);
      } catch (error) {
        console.log(`‚ö†Ô∏è Erro ao criar fun√ß√£o de cache: ${error.message}`);
      }
    }

    // 3. Criar √≠ndices compostos para queries complexas
    console.log("\n3. Criando √≠ndices compostos...");

    const compositeIndexes = [
      "CREATE INDEX IF NOT EXISTS idx_sales_attendant_date ON sales(attendant_id, created_at DESC)",
      "CREATE INDEX IF NOT EXISTS idx_sales_client_date ON sales(client_phone, created_at DESC)",
      "CREATE INDEX IF NOT EXISTS idx_goals_attendant_active ON goals(attendant_id, is_active, end_date)",
      "CREATE INDEX IF NOT EXISTS idx_notifications_attendant_read ON notifications(attendant_id, is_read, created_at DESC)",
      "CREATE INDEX IF NOT EXISTS idx_achievements_attendant_date ON achievements(attendant_id, achieved_at DESC)",
    ];

    for (const indexQuery of compositeIndexes) {
      try {
        await pool.query(indexQuery);
        console.log(`‚úÖ √çndice composto criado: ${indexQuery.split(" ")[2]}`);
      } catch (error) {
        console.log(
          `‚ö†Ô∏è √çndice composto j√° existe ou erro: ${indexQuery.split(" ")[2]}`
        );
      }
    }

    // 4. Configurar particionamento para tabelas grandes
    console.log("\n4. Configurando particionamento...");

    const partitioningQueries = [
      `CREATE TABLE IF NOT EXISTS sales_partitioned (
         LIKE sales INCLUDING ALL
       ) PARTITION BY RANGE (created_at)`,

      `CREATE TABLE IF NOT EXISTS sales_2024 PARTITION OF sales_partitioned
       FOR VALUES FROM ('2024-01-01') TO ('2025-01-01')`,

      `CREATE TABLE IF NOT EXISTS sales_2025 PARTITION OF sales_partitioned
       FOR VALUES FROM ('2025-01-01') TO ('2026-01-01')`,
    ];

    for (const partitionQuery of partitioningQueries) {
      try {
        await pool.query(partitionQuery);
        console.log(`‚úÖ Particionamento configurado`);
      } catch (error) {
        console.log(`‚ö†Ô∏è Erro no particionamento: ${error.message}`);
      }
    }

    // 5. Configurar monitoramento de performance
    console.log("\n5. Configurando monitoramento...");

    const monitoringQueries = [
      `CREATE EXTENSION IF NOT EXISTS pg_stat_statements`,

      `CREATE OR REPLACE VIEW v_performance_metrics AS
       SELECT 
         schemaname,
         tablename,
         n_tup_ins as inserts,
         n_tup_upd as updates,
         n_tup_del as deletes,
         n_live_tup as live_tuples,
         n_dead_tup as dead_tuples,
         last_vacuum,
         last_autovacuum,
         last_analyze,
         last_autoanalyze
       FROM pg_stat_user_tables
       ORDER BY n_live_tup DESC`,

      `CREATE OR REPLACE VIEW v_slow_queries AS
       SELECT 
         query,
         calls,
         total_time,
         mean_time,
         rows,
         shared_blks_hit,
         shared_blks_read
       FROM pg_stat_statements
       WHERE mean_time > 100
       ORDER BY mean_time DESC
       LIMIT 20`,

      `CREATE OR REPLACE VIEW v_index_usage AS
       SELECT 
         schemaname,
         tablename,
         indexname,
         idx_scan,
         idx_tup_read,
         idx_tup_fetch
       FROM pg_stat_user_indexes
       ORDER BY idx_scan DESC`,
    ];

    for (const monitoringQuery of monitoringQueries) {
      try {
        await pool.query(monitoringQuery);
        console.log(`‚úÖ Monitoramento configurado`);
      } catch (error) {
        console.log(`‚ö†Ô∏è Erro no monitoramento: ${error.message}`);
      }
    }

    // 6. Configurar backup autom√°tico
    console.log("\n6. Configurando backup autom√°tico...");

    const backupQueries = [
      `CREATE OR REPLACE FUNCTION create_backup()
       RETURNS TEXT AS $$
       DECLARE
         backup_filename TEXT;
       BEGIN
         backup_filename := 'backup_' || TO_CHAR(NOW(), 'YYYY_MM_DD_HH24_MI_SS') || '.sql';
         
         -- Aqui voc√™ pode adicionar l√≥gica para executar pg_dump
         -- Por enquanto, apenas retornamos o nome do arquivo
         RETURN backup_filename;
       END;
       $$ LANGUAGE plpgsql`,

      `CREATE OR REPLACE FUNCTION cleanup_old_backups()
       RETURNS VOID AS $$
       BEGIN
         -- L√≥gica para limpar backups antigos
         -- Implementar conforme necess√°rio
         NULL;
       END;
       $$ LANGUAGE plpgsql`,
    ];

    for (const backupQuery of backupQueries) {
      try {
        await pool.query(backupQuery);
        console.log(`‚úÖ Fun√ß√£o de backup criada`);
      } catch (error) {
        console.log(`‚ö†Ô∏è Erro na fun√ß√£o de backup: ${error.message}`);
      }
    }

    // 7. Configurar alertas e notifica√ß√µes
    console.log("\n7. Configurando alertas...");

    const alertQueries = [
      `CREATE OR REPLACE FUNCTION check_database_health()
       RETURNS TABLE (
         check_name TEXT,
         status TEXT,
         message TEXT
       ) AS $$
       BEGIN
         RETURN QUERY
         SELECT 
           'Connection Pool'::TEXT,
           CASE WHEN COUNT(*) > 0 THEN 'OK' ELSE 'ERROR' END,
           'Active connections: ' || COUNT(*)::TEXT
         FROM pg_stat_activity 
         WHERE state = 'active';
         
         RETURN QUERY
         SELECT 
           'Table Sizes'::TEXT,
           CASE WHEN SUM(pg_total_relation_size(schemaname||'.'||tablename)) < 1073741824 THEN 'OK' ELSE 'WARNING' END,
           'Total size: ' || pg_size_pretty(SUM(pg_total_relation_size(schemaname||'.'||tablename)))
         FROM pg_tables 
         WHERE schemaname = 'public';
         
         RETURN QUERY
         SELECT 
           'Dead Tuples'::TEXT,
           CASE WHEN SUM(n_dead_tup) < SUM(n_live_tup) * 0.1 THEN 'OK' ELSE 'WARNING' END,
           'Dead tuples: ' || SUM(n_dead_tup)::TEXT
         FROM pg_stat_user_tables;
       END;
       $$ LANGUAGE plpgsql`,
    ];

    for (const alertQuery of alertQueries) {
      try {
        await pool.query(alertQuery);
        console.log(`‚úÖ Fun√ß√£o de alerta criada`);
      } catch (error) {
        console.log(`‚ö†Ô∏è Erro na fun√ß√£o de alerta: ${error.message}`);
      }
    }

    // 8. Otimizar configura√ß√µes de conex√£o
    console.log("\n8. Otimizando configura√ß√µes de conex√£o...");

    const connectionOptimizations = [
      "SET tcp_keepalives_idle = 600",
      "SET tcp_keepalives_interval = 60",
      "SET tcp_keepalives_count = 3",
      "SET log_min_messages = warning",
      "SET log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '",
    ];

    for (const optimization of connectionOptimizations) {
      try {
        await pool.query(optimization);
        console.log(
          `‚úÖ Otimiza√ß√£o de conex√£o aplicada: ${optimization.split(" ")[1]}`
        );
      } catch (error) {
        console.log(
          `‚ö†Ô∏è Otimiza√ß√£o n√£o aplicada: ${optimization.split(" ")[1]}`
        );
      }
    }

    console.log("\nüéâ Otimiza√ß√£o do servidor conclu√≠da!");
    console.log("\nüìä Resumo das otimiza√ß√µes:");
    console.log("‚úÖ Configura√ß√µes de performance aplicadas");
    console.log("‚úÖ Fun√ß√µes de cache criadas");
    console.log("‚úÖ √çndices compostos adicionados");
    console.log("‚úÖ Particionamento configurado");
    console.log("‚úÖ Monitoramento ativado");
    console.log("‚úÖ Backup autom√°tico configurado");
    console.log("‚úÖ Alertas de sa√∫de criados");
    console.log("‚úÖ Conex√µes otimizadas");
  } catch (error) {
    console.error("‚ùå Erro durante a otimiza√ß√£o:", error);
    throw error;
  } finally {
    await pool.end();
  }
}

// Executar otimiza√ß√£o
optimizeServer().catch(console.error);
